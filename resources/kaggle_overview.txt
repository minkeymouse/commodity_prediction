Overview
In this competition, you are challenged to develop a model capable of predicting future commodity returns using historical data from London Metal Exchange (LME), Japan Exchange Group (JPX), US Stock, and Forex markets. Leveraging insights from these diverse datasets is key to building stable, long-term forecasts crucial for optimizing trading strategies and managing risk in global commodity markets.



Dataset Description
This competition dataset consists of multiple financial time series data obtained from markets around the world. The dataset various financial instruments such as metals, futures, US stocks, and foreign exchange. Participants are challenged to develop models that predict the returns of multiple target financial time series.

Competition Phases and Data Updates
The competition will proceed in two phases:

A model training phase with a test set of roughly three months of historical data. Because these prices are publicly available leaderboard scores during this phase are not meaningful.
A forecasting phase with a test set to be collected after submissions close. You should expect this test set to be about the same size as the test set in the first phase.
During the forecasting phase the evaluation API will serve test data from the beginning of the public set to the end of the private set.

Files
train.csv Historic finance data retlated to commodities such as closing prices, trading volumes, foreign exchange rates, and so on.

date_id - A single UTC date. Due to time zone and holiday differences, some entire exchanges may not have traded on a given date.
[time_series_identifier] - Each security includes a two or three letter prefix that denotes the origin of the trading activity: LME (London Mercantile Exchange), JPX (Japanese Securities Exchange), US (various US stock exchanges), and FX (foreign exchange).
test.csv A mock test set representing the structure of the unseen test set. The test set used for the public leaderboard set is a copy of the last 90 dates in the train set. As a result, the public leaderboard scores are not meaningful. The unseen copy of this file served by the evaluation API may be updated during the model training phase.

date_id
[time_series_identifier]
is_scored - Whether this row is included in the evaluation metric calculation. During the model training phase this will be true for the first 90 rows only. Test set only.
train_labels.csv The targets consist of log returns of one financial instrument or the differences between a pair of financial instruments. See target_pairs.csv for the details of each target column.

date_id
target_[0-423]
lagged_test_labels/test_labels_lag_[1-4].csv The same content as train_labels.csv, but split into separate files for each lag. This will be served by the evaluation API.

date_id - In this file, indicates the date the labels are released by the evaluation API.
label_date_id - The date id when this label would have been predicted for a perfect submission.
target_pairs.csv Details of the inputs for each target calculation. See this notebook for an illustration of how to use this information to go from price data to targets.

target - The name of the matching target column.
lag - The number of days of lag.
pair - The security or securities.
kaggle_evaluation/ Files used by the evaluation API. See the demo submission for an illustration of how to use the API.

Description
The Challenge: Aiming for More Accurate Commodity Price Forecasting
This competition tackles the critical need for more accurate and stable long-term commodity price predictions. Getting these predictions right has significant implications for both businesses and the global economy. Inaccurate forecasts can lead to suboptimal trading strategies, poor investment decisions, and increased financial risk for companies involved in commodity markets. By encouraging the development of advanced AI models that can accurately predict future commodity returns using historical data from LME, JPX, US Stock, and Forex, this competition aims to directly improve the precision of financial forecasting and enable the optimization of automated trading strategies.

In particular, participants are challenged to predict price-difference series—derived from the time-series differences between two distinct assets’ prices—to extract robust price-movement signals as features and deploy AI-driven trading techniques that turn those signals into sustainable trading profits.

Why It's Important: Stable Markets and Smarter Decisions
Accurate commodity price prediction is crucial for reducing financial risk and ensuring stability in the global market. Currently, the inherent volatility and unpredictability of commodity prices create several problems. Companies struggle with resource allocation, budgeting, and investment planning, often resulting in financial losses and inefficient operations. Inaccurate forecasts can also contribute to market instability and price fluctuations, negatively impacting producers, consumers, and investors alike. If this problem could be solved, businesses could optimize their trading strategies, make more informed investment decisions, and manage risk more effectively. This would lead to more efficient resource allocation, reduced price volatility, and a more stable and predictable global commodity market.

Current Limitations and What We Hope to Achieve
Advanced AI algorithms and high-precision models are currently employed for commodity market prediction, utilizing historical price datasets from LME, JPX, US Stock, and Forex. While these models show promise, they often encounter limitations in consistently achieving high accuracy across diverse market conditions and over extended time horizons. Existing models may exhibit over-reliance on specific data patterns, lacking the adaptability required to navigate the dynamic and constantly evolving nature of financial markets. This competition seeks a more diverse and robust set of algorithms to achieve reliable and stable long-term predictions.

Acknowledgements
AlpacaTech Co., Ltd. provided technical support for problem design and data creation in this competition.
The Forex data for this competition was supplied via the Exchange Rates API from APILayer.

Evaluation
The competition's metric is a variant of the Sharpe ratio, computed by dividing the mean Spearman rank correlation between the predictions and targets by the standard deviation. The metric code is available here.

Submission File
You must submit to this competition using the provided evaluation API, which ensures that models do not peek forward in time. See this example notebook for more details.

Timeline
This is a forecasting competition with an active training phase and a separate forecasting phase where models will be run against real market returns.
Training Timeline:
July 24, 2025 - Start Date.
September 29, 2025 - - Entry Deadline. You must accept the competition rules before this date in order to compete.
September 29, 2025 - Team Merger Deadline. This is the last day participants may join or merge teams.
October 6, 2025 - Final Submission Deadline.
All deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.

Forecasting Timeline:
Starting after the final submission deadline there will be periodic updates to the leaderboard to reflect market data updates that will be run against selected notebooks.

January 16, 2026 - Competition End Date

Code Requirements

Submissions to this competition must be made through Notebooks. In order for the "Submit" button to be active after a commit, the following conditions must be met:

CPU Notebook <= 8 hours run-time
GPU Notebook <= 8 hours run-time
Internet access disabled
Forecasting Phase
The run-time limits for both CPU and GPU notebooks will be extended to 9 hours during the forecasting phase. You must ensure your submission completes within that time.

The extra hour is to help protect against time-out failures due to the extended size of the test set. You are still responsible for ensuring your submission completes within the 9 hour limit, however. See the Data page for details on the extended test set during the forecasting phase.

Please see the Code Competition FAQ for more information on how to submit. And review the code debugging doc if you are encountering submission errors.

